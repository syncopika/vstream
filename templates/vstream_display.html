<html>

	<head>
		<title>vstream display</title>
		<script src="//cdnjs.cloudflare.com/ajax/libs/socket.io/2.2.0/socket.io.js" integrity="sha256-yr4fRk/GU1ehYJPAs8P4JlTgu0Hdsp4ZKrx8bDEDC3I=" crossorigin="anonymous"></script>
	</head>
	
	<style>
		#main{
			font-family: monospace;
			text-align: center;
			top: 5%;
			position: relative;
			display: block;
		}
		#display{
			border: #000 solid 1px;
		}
	</style>
	
	<body>
		<div id='main'>
			<h3> vstream display </h3>
			
			<canvas id='display' width='400px' height='400px'>
			</canvas>
			
			<br />
			<br />
			
			<button id='calibrate'> calibrate </button>
			<button id='toggleStream'> pause/continue </button>
			<br />
			
			<h3 id='currAnchorPosition'></h3>
			<br />
			
			<h3 id='currentJawDist'></h3>
			<br />
			
			<h2> translation: </h2>
			<h3 id='currentAction'></h3>
			<br />
			
			<h2> z-axis rotation: </h2>
			<h3 id='zAxisRotation'></h3>
			<br />
			
			<h3 id='zAxisRotation2'></h3>
			<br />
			
			<h2> y-axis rotation: </h2>
			<h3 id='yAxisRotation'></h3>
			<br />
			
		</div>
	</body>


	<script>
		const socket = io();
		let streamPaused = false;
		let calibrate = false;
		
		// maybe instead of anchor points, we just save all the points of the previous frame to compare with. :>
		// let's use landmark coordinate number 27 and 30 (that's part of the nose)
		let anchorPoint = null; // should be a map with just x and y as keys, i.e. {'x': 0, 'y': 0}
		let anchorPoint2 = null; // use this point to create a 'normal' vector with anchorPoint.
		let lastJawEndptDist = null;
		let rightJawEnd = null;
		let leftJawEnd = null;
		let updateAnchorPoint = false;
		let prevAnchor = null;
		let currAnchor = null;
		
		function toggleStream(){
			streamPaused = !streamPaused;
			socket.emit("toggleStream", streamPaused);
		}
		
		document.getElementById("toggleStream").addEventListener("click", (evt) => {
			console.log("toggling stream...");
			toggleStream();
		});
		
		
		function getDistance(point1, point2){
			return Math.sqrt(Math.pow((point2.x - point1.x),2) + Math.pow((point2.y - point1.y),2));
		}
		
		// pass in 2 coordinates
		// https://stackoverflow.com/questions/14066933/direct-way-of-computing-clockwise-angle-between-2-vectors
		function getAngle(vec1, vec2){
			let dot = (vec1.x * vec2.x) + (vec1.y * vec2.y);
			let det = (vec1.x * vec2.y) - (vec1.y * vec2.x);
			let angle = Math.atan2(det, dot) * (180 / Math.PI);
			return angle;
		}
		
		// set the initial nose/anchor point that we can use to figure out when a rotation is happening
		function calibrateAnchor(pt1, pt2){
			// using global vars here 
			anchorPoint = pt1;
			anchorPoint2 = pt2;
		}
		
		function inRange(x1, x2, rangeLimit){
			return (x1 <= x2 + rangeLimit) && (x1 >= x2 - rangeLimit);
		}
		
		document.getElementById('calibrate').addEventListener('click', (evt) => {
			calibrate = !calibrate;
		});
		
		// handle receiving facial landmark coordinate data 
		socket.on('landmarkCoordinates', (data) => {
			let landmark_data = JSON.parse(data);
			
			if(landmark_data.length > 0){
			
				////////// start movement calculation stuff (i.e. determine how to rotate/translate head)
				if(calibrate){
					//calibrateAnchor(landmark_data[27], landmark_data[30]);
					calibrate = !calibrate;
					prevAnchor = landmark_data[27];
				}
			
				rightJawEnd = landmark_data[0];
				leftJawEnd = landmark_data[16];
				if(lastJawEndptDist === null){
					lastJawEndptDist = getDistance(leftJawEnd, rightJawEnd);
				}else{
					// note! moving the head up and down can trigger similar changes to moving backwards/forwards :<
					let currDist = getDistance(leftJawEnd, rightJawEnd);
					
					// how much room can we give before something is actually considered moving towards or away from the cam?
					// we should allow for some small dist changes before translating the avatar forwards or backwards
					if(currDist < lastJawEndptDist - 2.5){
						// moving backwards / away from camera 
						// by how much?
						document.getElementById('currentAction').textContent = "moving backwards...";
					}else if(currDist > lastJawEndptDist + 2.5){
						// moving forwards / towards camera
						document.getElementById('currentAction').textContent = "moving forwards...";
					}else{
						document.getElementById('currentAction').textContent = "";
					}
					
					//document.getElementById('currentJawDist').textContent = "curr jaw endpoints distance: " + currDist;
					
					// reset
					lastJawEndptDist = currDist;
				}
				
				
				// are we rotating the head about the z-axis (the axis coming at the camera), i.e. head tilts sideways
				if(prevAnchor){
				
					currAnchor = landmark_data[27]; // we just need one point?

					//let currAnchor2 = landmark_data[30];
					let angle = getAngle(currAnchor, prevAnchor);
					//document.getElementById('zAxisRotation2').textContent = "z-axis angle: " + angle + " degrees. currAnchor1.y: " + currAnchor1.y + ", anchorPoint.y: " + anchorPoint.y;
					if(Math.abs(angle) > 2 && !(inRange(leftJawEnd.y, rightJawEnd.y, 3.0))){
						document.getElementById('zAxisRotation').textContent = "rotate about z-axis! angle: " + angle + " degrees.";
						updateAnchorPoint = true;
					}else{
						document.getElementById('zAxisRotation').textContent = "";
					}
					document.getElementById('currAnchorPosition').textContent = "curr anchor position => x: " + currAnchor.x + ", y: " + currAnchor.y;
				}
				
				// are we rotating about the y-axis (axis going up/down). captures head rotation when looking left/right
				// look at distance between nose point and jaw endpoints
				// uh but what if the head is tilted??? we can use the jaw endpoints to help (look at their y-values?)
				if(prevAnchor){
				
					currAnchor = landmark_data[27]; // we just need one point?
					
					// need to make sure the jaw endpoints are pretty much at the same level 
					// and check to see that the curr anchor pt. is 
					let diff = currAnchor.x - prevAnchor.x;
					let turnDirection = diff > 0.0 ? "left" : "right";
					
					if(inRange(leftJawEnd.y, rightJawEnd.y, 1.0) && !(inRange(currAnchor.x, prevAnchor.x, 2.0))){
						// if the curr pos of currAnchor1 is more than a certain amount away from the prev anchorPoint along the x-axis
						// and as long as the y-coords of the jaw endpoints are pretty similar
						updateAnchorPoint = true;
						document.getElementById('yAxisRotation').textContent = "rotate about y-axis! direction: " + turnDirection + ", currAnchor.x: " + currAnchor.x + ", prevAnchor.x: " + prevAnchor.x;
					}else{
						document.getElementById('yAxisRotation').textContent = "";
					}
					
				}
				
				
				// are we rotating about the x-axis (axis going left/right). captures nodding motions.
				// can use nose anchor point and just check y-axis?
				
				
				
				if(updateAnchorPoint){
					prevAnchor = currAnchor;
					updateAnchorPoint = false;
				}
				
				
				// are we translating the head? i.e. moving the head left/right without any rotations?
				// just sample a few points and get the diff?
				
				/////////// end movement calculation stuff
				
			
				let canvas = document.getElementById("display");
				let context = canvas.getContext("2d");
				
				// clear the canvas 
				context.clearRect(0, 0, 400, 400);
				
				// draw on the canvas 
				landmark_data.forEach((coord) => {
					context.fillRect(coord.x, coord.y, 2, 2);
				});
				
				// connect the dots
				// fortunately, the coords should be organized so it's easy to connect the parts
				// see: https://www.pyimagesearch.com/2017/04/10/detect-eyes-nose-lips-jaw-dlib-opencv-python/
				let coordsToSkip = new Set([16, 21, 26, 35, 41, 47, 67]); // 7 regions === 7 lines to draw
				for(let i = 0; i <= landmark_data.length-1; i++){
					// do not connect the last coord for each facial region (i.e. mouth, node, jaw, etc.) to anything
					
					// fix mouth (special case) 
					if(i === 67){
						// needs to connect with 60
						context.beginPath();
						context.moveTo(landmark_data[i].x, landmark_data[i].y);
						context.lineTo(landmark_data[60].x, landmark_data[60].y);
						context.stroke();
					}else if(coordsToSkip.has(i)){
						continue;
					}else{
						let x = landmark_data[i].x;
						let y = landmark_data[i].y;
						let x2 = landmark_data[i+1].x;
						let y2 = landmark_data[i+1].y;
						context.beginPath();
						context.moveTo(x, y);
						context.lineTo(x2, y2);
						context.stroke();
					}
				}
			}
			//console.log(landmark_data);
			//console.log("==========================")
		});
		
	</script>



</html>