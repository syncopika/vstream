<html>

	<head>
		<title>vstream display</title>
		<script src="//cdnjs.cloudflare.com/ajax/libs/socket.io/2.2.0/socket.io.js" integrity="sha256-yr4fRk/GU1ehYJPAs8P4JlTgu0Hdsp4ZKrx8bDEDC3I=" crossorigin="anonymous"></script>
		<!--
		<script src='https://cdnjs.cloudflare.com/ajax/libs/three.js/108/three.min.js'></script>
		<script src='static/GLTFLoader.js'></script>
		-->
		<script src="{{ url_for('static', filename='node_modules/three/build/three.js')}}"></script>
		
		<!-- Flask issue with ES6 modules :( -->
		<!--<script src="{{ url_for('static', filename='node_modules/three/examples/jsm/loaders/GLTFLoader.js') }}" type="module"></script>-->
		
		<script src='static/GLTFLoader.js'></script>
		
	</head>
	
	<style>
		#main{
			font-family: monospace;
			text-align: center;
			top: 5%;
			position: relative;
			display: block;
		}
		canvas{
			border: #000 solid 1px;
		}
		#container{
			width: 400px;
			height: 400px;
			margin: 0 auto;
			display: inline-block;
		}
	</style>
	
	<body>
		<div id='main'>
			<h3> vstream display </h3>
			
			<div id='show'>
				<canvas id='display' width='400px' height='400px'>
				</canvas>
			
				<div id='container'>
				</div>
			</div>
			
			<br />
			<br />
			
			<button id='calibrate'> calibrate </button>
			<button id='toggleStream'> pause/continue </button>
			<!--<button id='toggleWireframe'> toggle wireframe </button>-->
			<br />
			
			
		</div>
	</body>


	<script>
	
		/* notes 
		
			oooh this looks good: https://github.com/auduno/clmtrackr
		
			potentially useful resources (mostly about morphing, but the warping step I think is really what we want):
			https://www.cs.toronto.edu/~mangas/teaching/320/slides/CSC320T12.pdf
			https://pdfs.semanticscholar.org/f528/d3e9ca5b8bf7e3b47aadce9f151a6467150a.pdf
			https://www.cs.uaf.edu/~olawlor/academic/thesis/ref/chen93interpolation.pdf -> 2.2 looks very relevant
			http://eeweb.poly.edu/~yao/EL5123/lecture12_ImageWarping.pdf
			
			https://stackoverflow.com/questions/28843938/three-js-how-to-create-new-morphing-geometry-if-i-have-all-necessary-buffers
			
		*/
	
		const socket = io();
		let streamPaused = false;
		let calibrate = false;
		let showWireframe = false;
		
		// maybe instead of anchor points, we just save all the points of the previous frame to compare with. :>
		// let's use landmark coordinate number 27 and 30 (that's part of the nose)
		//let anchorPoint = null; // should be a map with just x and y as keys, i.e. {'x': 0, 'y': 0}
		//let anchorPoint2 = null; // use this point to create a 'normal' vector with anchorPoint.
		let lastJawEndptDist = null;
		let rightJawEnd = null;
		let leftJawEnd = null;
		let updateAnchorPoint = false;
		let prevAnchor = null;
		let currAnchor = null;
		
		const mapping = {};
		
		const baselineMouthCalibration = {
			"top2d": {}, // x,y coord
			"bottom2d": {},
			"left2d": {}, // left corner 
			"right2d": {},
			"dist2d": 0, // distance between the top and bottom pts for the 2d canvas (landmark pts)
			"left3d": {},
			"right3d": {}
			//"dist3d": 0 // distance between the top and bottom pts for the model
		};
		
		function toggleStream(){
			streamPaused = !streamPaused;
			socket.emit("toggleStream", streamPaused);
		}
		
		document.getElementById("toggleStream").addEventListener("click", (evt) => {
			console.log("toggling stream...");
			toggleStream();
		});
		

		function getDistance(point1, point2){
			return Math.sqrt(Math.pow((point2.x - point1.x),2) + Math.pow((point2.y - point1.y),2));
		}
		
		// pass in 2 coordinates
		// https://stackoverflow.com/questions/14066933/direct-way-of-computing-clockwise-angle-between-2-vectors
		function getAngle(vec1, vec2){
			let dot = (vec1.x * vec2.x) + (vec1.y * vec2.y);
			let det = (vec1.x * vec2.y) - (vec1.y * vec2.x);
			let angle = Math.atan2(det, dot) * (180 / Math.PI);
			return angle;
		}
		
		// set the initial nose/anchor point that we can use to figure out when a rotation is happening
		function calibrateBaseline(landmarkData, map){

			// map points from landmark coords to face meshes
			
			for(let part in avatarParts){
			
				if(part === "mouth"){
					// let's only care about the mouth corners and one top/bottom vert
					let top = landmarkData[62];
					let bottom = landmarkData[66];

					let leftMouthCorner = landmarkData[60];
					let rightMouthCorner = landmarkData[64];
					
					// record the distance between the bottom and top most mouth vertices
					map['mouth'] = {
						'vertical': {
							'baseline': getDistance(top, bottom),
							'previous': 0
						},
						'horizontal': {
							'baseline': getDistance(leftMouthCorner, rightMouthCorner),
							'previous': 0
						}
					}
				}
				
				if(part === "leftEye"){
					let top = landmarkData[38];
					let bottom = landmarkData[41];
					
					map['leftEye'] = {
						'vertical': {
							'baseline': getDistance(top, bottom),
							'previous': 0
						}
					}
				}
				
				if(part === "rightEye"){
					let top = landmarkData[44];
					let bottom = landmarkData[46];
					map['rightEye'] = {
						'vertical': {
							'baseline': getDistance(top, bottom),
							'previous': 0
						}
					}
				}
				
				if(part === "leftEyebrow"){
					// the eyebrow will be treated a little differently in that 
					// I think using the rightmost coord of the left eyebrow (left when facing the screen,
					// so the coord closest to the top of the line going down the nose)
					// and the leftmost coord of the right eyebrow and comparing distance between the coord
					// at the top of the nose can help
					
					let middle = landmarkData[27];
					let right = landmarkData[21];
					map['leftEyebrow'] = {
						'dist': {
							'baseline': getDistance(right, middle),
							'previous': 0
						}
					}
				}
				
				if(part === "rightEyebrow"){
					let middle = landmarkData[27];
					let left = landmarkData[22];
					map['rightEyebrow'] = {
						'dist': {
							'baseline': getDistance(left, middle),
							'previous': 0
						}
					}
				}
				
				if(part === "head"){
					// jaw technically?
				}
			
			}
			
			
			
		}
		
		// pass in x and y coords from 2d space
		// because of how 2d canvas coordinates are (0,0 being the top left corner, no neg. coords),
		// we need to convert so we can know where a 2d coord can get mapped to in 3d space
		function convert2dCoords(x, y, width, height){
			let newCoords = {};
			if(x > width/2){
				newCoords.x = x;
			}
		}
	
		
		function inRange(x1, x2, rangeLimit){
			return (x1 <= x2 + rangeLimit) && (x1 >= x2 - rangeLimit);
		}
		
		document.getElementById('calibrate').addEventListener('click', (evt) => {
			calibrate = !calibrate;
		});
		
		
		
		//////////////////////////////////////////// three js stuff
		
		function getModel(modelFilePath, name){
			return new Promise((resolve, reject) => {
				loader.load(
					modelFilePath,
					function(gltf){
						if(gltf.animations.length > 0){
							console.log(gltf.animations);
						}

						var faceParts = [];
						gltf.scene.traverse((child) => {

							if(child.type === "Mesh"){
								
								console.log(child);
								let material = child.material;
								let geometry = child.geometry;
								
								// https://stackoverflow.com/questions/52569738/how-to-access-single-vertices-of-mesh-loaded-with-gltfloader-in-three-js
								let obj = new THREE.Mesh(geometry, material);
								obj.scale.x = child.scale.x * 5;
								obj.scale.y = child.scale.y * 5;
								obj.scale.z = child.scale.z * 5;
								
								obj.name = child.name;

								//resolve(obj);
								faceParts.push(obj);
								
							}else{
								//console.log(child.type);
							}
						});
						resolve(faceParts);
					},
					// called while loading is progressing
					function(xhr){
						console.log( (xhr.loaded / xhr.total * 100) + '% loaded' );
					},
					// called when loading has errors
					function(error){
						console.log('An error happened');
						console.log(error);
					}
				);
			});
		}
		
		const loader = new THREE.GLTFLoader();
		let loadedModels = [];
		
		const avatarParts = {
			"head": null,
			"leftEyebrow": null,
			"leftEye": null,
			"rightEyebrow": null,
			"rightEye": null,
			"mouth": null
		};
		
		const group = new THREE.Group();
		let meshLoaded = false;
		
		const el = document.getElementById("container");
		const renderer = new THREE.WebGLRenderer();
		const fov = 60;
		const camera = new THREE.PerspectiveCamera(fov, 1.0, 0.01, 1000);
		const scene = new THREE.Scene();
		scene.background = new THREE.Color(0xffffff);	
		
		renderer.shadowMap.enabled = true;
		renderer.setSize(400, 400);	
		el.appendChild(renderer.domElement);
		
		camera.position.set(0,2,25);
		scene.add(camera);
		
		
		// https://discourse.threejs.org/t/solved-glb-model-is-very-dark/6258
		// should always use a hemisphere light!
		var hemiLight = new THREE.HemisphereLight(0xffffff, 0x444444);
		hemiLight.position.set(0, 200, 0);
		scene.add(hemiLight);
		
		// basic_avatar_head-edit3.gltf is experimenting with a different kind of mesh setup for the eye.
		// basic_avatar_head-edit2.gltf is the most up-to-date non-experimental
		loadedModels.push(getModel('../static/basic_avatar_head-edit4.gltf', 'avatar'));

		Promise.all(loadedModels).then((objects) => {
			objects.forEach((meshList) => {
				
				var count = 0;
				
				// note that i'm assuming a list of meshes coming in. change this later
				meshList.forEach((mesh) => {
					//console.log(mesh);
					
					if(showWireframe){
						var wireframe = new THREE.WireframeGeometry(mesh.geometry);
						var line = new THREE.LineSegments(wireframe);
						line.material.depthTest = false;
						line.material.opacity = .8;
						line.material.transparent = true;
						group.add(line);
					}else{
						group.add(mesh);
					}
				
					bgAxesHelper = new THREE.AxesHelper(10);
					group.add(bgAxesHelper);
					//mesh.position.set(0,0,0);
					
					let theMesh = showWireframe ? line : mesh;
					let meshGeometry = showWireframe ? line.geometry : mesh;  // kinda misleading...
					
					if(mesh.name === "head"){
						// the head 
						avatarParts.head = meshGeometry;
					}
					
					// loading the meshes is not always in the same order!!!
					if(mesh.name === "rightEye"){
						// right eye
						theMesh.position.set(-3.5,3,0);
						avatarParts.rightEye = meshGeometry;
					}
					
					if(mesh.name === "leftEye"){
						// left eye
						theMesh.position.set(3.5,3,0);
						avatarParts.leftEye = meshGeometry;
					}
					
					if(mesh.name === "leftEyebrow"){
						// left eyebrow
						theMesh.position.set(3.5,6.5,0);
						avatarParts.leftEyebrow = meshGeometry;
					}
					
					if(mesh.name === "rightEyebrow"){
						// right eyebrow
						theMesh.position.set(-3.5,6.5,0);
						avatarParts.rightEyebrow = meshGeometry;
					}
					
					if(mesh.name === "mouth"){
						// mouth
						theMesh.position.set(0,-5,0);
						avatarParts.mouth = meshGeometry;
					}
					
					count++;
					
					if(count === 6){
						//mesh.castShadow = true;
						console.log(avatarParts);
						group.position.set(0,0,0);
						avatar = group;
					
						scene.add(group);

						renderer.render(scene, camera);
						meshLoaded = true;
					}
				});
			});
		});
		
		function clamp(val, min, max){
			val = val > 1.0 ? 1.0 : val;
			val = val < 0.0 ? 0.0 : val;
			return val;
		}
		
		function handleMouthMovement(mapping, landmark_data, avatarParts){
			let mouthVertical = mapping['mouth'].vertical;
			let mouthHorizontal = mapping['mouth'].horizontal;
			
			// what's the delta from the last distance or the baseline distance we got when we calibrated?
			let lastVert;
			let lastHorz;
			lastVert = mouthVertical.previous === 0 ? mouthVertical.baseline : mouthVertical.previous;
			lastHorz = mouthHorizontal.previous === 0 ? mouthHorizontal.baseline : mouthHorizontal.previous;
			
			let top2d = landmark_data[62];
			let bottom2d = landmark_data[66];
			let rightMouthCorner = landmark_data[64];
			let leftMouthCorner = landmark_data[60];
			
			let currDistVert = getDistance(top2d, bottom2d);
			let currDistHorz = getDistance(leftMouthCorner, rightMouthCorner);
			
			// to minimize tiny fluctuations, set a minimum distance to be achieved before mouth movement is allowed 
			if(Math.abs(currDistVert - lastVert) <= 2.0){
				return;
			}
			
			let deltaVert = (currDistVert - lastVert) / 8;
			let deltaHorz = (currDistHorz - lastHorz) / 8;
			
			let currMouthVertical = avatarParts.mouth.morphTargetInfluences[0]; // control vertical movement of mouth 
			let currMouthHorizontal = avatarParts.mouth.morphTargetInfluences[2]; // control horizontal movement of mouth corners
			
			currMouthVertical = clamp(currMouthVertical + deltaVert, 0.0, 1.0); // clamp (make a function for this?)
			avatarParts.mouth.morphTargetInfluences[0] = currMouthVertical;
			mapping['mouth'].vertical.previous = currDistVert; // update previous with curr distance 
			
			// work on moving the ends of the mouth along the x axis as well!
			// got shape keys! this is easy. just figure out the change in distance between the 2 mouth corners. yay
			currMouthHorizontal = clamp(currMouthHorizontal + deltaHorz, 0.0, 1.0);
			avatarParts.mouth.morphTargetInfluences[2] = currMouthHorizontal;
			mapping['mouth'].horizontal.previous = currDistHorz;
			
			// support o mouth movement (i.e. forming an o)
			// make sure we have some horizontal movement and vertical movement
			if(currDistHorz < mouthHorizontal.baseline - 2.0 && currMouthVertical > 0.3){
				// let's say baseline - 5.0 === maximum o mouth influence.
				// max influence == 1, no influence == 0
				// interpolation time 
				let max = mouthHorizontal.baseline - 5.0; // the distance at which the o mouth will have maximum influence
				let currVal = Math.min(currDistHorz / max, max);
				avatarParts.mouth.morphTargetInfluences[1] = currVal;
			}else{
				avatarParts.mouth.morphTargetInfluences[1] = 0;
			}
		}
		
		function handleEyeMovement(mapping, landmark_data, avatarParts){
			// ok so I made this a bit confusing, sorry -__-
			// the shape key is closeEye so the larger the morph influence value, the more closed the eye gets.
			// so 1.0 == closed eye, 0.0 == open eye. :/
			
			let leftEyeVertical = mapping['leftEye'].vertical;
			let rightEyeVertical = mapping['rightEye'].vertical;
			let lastVertLeft, lastVertRight;
			let minDelta = 1.8;
			
			lastVertLeft = leftEyeVertical.previous === 0 ? leftEyeVertical.baseline : leftEyeVertical.previous;
			lastVertRight = rightEyeVertical.previous === 0 ? rightEyeVertical.baseline : rightEyeVertical.previous;

			let currDistVertLeft = getDistance(landmark_data[38], landmark_data[41]);
			let currDistVertRight = getDistance(landmark_data[44], landmark_data[46]);
			
			let deltaVertLeft = (currDistVertLeft - lastVertLeft);
			if(Math.abs(deltaVertLeft) > minDelta){
				deltaVertLeft /= 3;
				let currEyeLeft = avatarParts.leftEye.morphTargetInfluences[0];
				
				currEyeLeft = clamp(currEyeLeft - deltaVertLeft, 0.0, 1.0); // if the eye is closing, deltaVertLeft should be a negative value (thus adding to currEyeLeft)
				
				avatarParts.leftEye.morphTargetInfluences[0] = currEyeLeft;
				mapping['leftEye'].vertical.previous = currDistVertLeft;
			}
			
			let deltaVertRight = (currDistVertRight - lastVertRight);
			if(Math.abs(deltaVertRight) > minDelta){
				deltaVertRight /= 3;
				let currEyeRight = avatarParts.rightEye.morphTargetInfluences[0];
				
				currEyeRight = clamp(currEyeRight - deltaVertRight, 0.0, 1.0);
				
				avatarParts.rightEye.morphTargetInfluences[0] = currEyeRight;
				mapping['rightEye'].vertical.previous = currDistVertRight;
			}
		}
		
		
		function handleEyebrowMovement(mapping, landmark_data, avatarParts){
			let left = mapping.leftEyebrow.dist;
			let right = mapping.rightEyebrow.dist;
			let minDelta = 1.2;
			
			let leftPrev = left.previous === 0 ? left.baseline : left.previous;
			let rightPrev = right.previous === 0 ? right.baseline : right.previous;
			
			let currDistLeft = getDistance(landmark_data[21], landmark_data[27]);
			let currDistRight = getDistance(landmark_data[22], landmark_data[27]);
			
			let deltaLeft = currDistLeft - leftPrev;
			if(Math.abs(deltaLeft) > minDelta && currDistLeft >= left.baseline){
				let newVal = deltaLeft / 3;
				let oldMorphVal = avatarParts.leftEyebrow.morphTargetInfluences[0];
				avatarParts.leftEyebrow.morphTargetInfluences[0] = clamp(oldMorphVal + newVal, 0.0, 1.0); // eyebrow up
				mapping.leftEyebrow.dist.previous = currDistLeft;
			}
			
			let deltaRight = currDistRight - rightPrev;
			if(Math.abs(deltaRight) > minDelta && currDistRight >= right.baseline){
				let newVal = deltaRight / 3;
				let oldMorphVal = avatarParts.rightEyebrow.morphTargetInfluences[0];
				avatarParts.rightEyebrow.morphTargetInfluences[0] = clamp(oldMorphVal + newVal, 0.0, 1.0); // eyebrow up
				mapping.rightEyebrow.dist.previous = currDistRight;
			}
			
			// what about eyebrow down???
			if(Math.abs(deltaLeft) > minDelta && currDistLeft < left.baseline){
				// we need to move the eyebrow down
				let newVal = deltaLeft / 3;
				let oldMorphVal = avatarParts.leftEyebrow.morphTargetInfluences[1];
				avatarParts.leftEyebrow.morphTargetInfluences[1] = clamp(oldMorphVal + newVal, 0.0, 1.0); // eyebrow down
				mapping.leftEyebrow.dist.previous = currDistLeft;
			}
			
			if(Math.abs(deltaRight) > minDelta && currDistRight < right.baseline){
				// we need to move the eyebrow down
				let newVal = deltaRight / 3;
				let oldMorphVal = avatarParts.rightEyebrow.morphTargetInfluences[1];
				avatarParts.rightEyebrow.morphTargetInfluences[1] = clamp(oldMorphVal + newVal, 0.0, 1.0); // eyebrow down
				mapping.rightEyebrow.dist.previous = currDistRight;
			}
		}
	
		///////////////////////////////////////////////////////////
		
		function updateCanvas(landmark_data, context){
			// clear the canvas 
			context.clearRect(0, 0, 400, 400);
			
			// draw on the canvas 
			landmark_data.forEach((coord) => {
				context.fillRect(coord.x, coord.y, 2, 2);
			});
			
			// connect the dots
			// fortunately, the coords should be organized so it's easy to connect the parts
			// see: https://www.pyimagesearch.com/2017/04/10/detect-eyes-nose-lips-jaw-dlib-opencv-python/
			let coordsToSkip = new Set([16, 21, 26, 35, 41, 47, 67]); // 7 regions === 7 lines to draw
			for(let i = 0; i <= landmark_data.length-1; i++){
				// do not connect the last coord for each facial region (i.e. mouth, node, jaw, etc.) to anything
				
				// fix mouth (special case) 
				if(i === 67){
					// needs to connect with 60
					context.beginPath();
					context.moveTo(landmark_data[i].x, landmark_data[i].y);
					context.lineTo(landmark_data[60].x, landmark_data[60].y);
					context.stroke();
				}else if(coordsToSkip.has(i)){
					continue;
				}else{
					let x = landmark_data[i].x;
					let y = landmark_data[i].y;
					let x2 = landmark_data[i+1].x;
					let y2 = landmark_data[i+1].y;
					context.beginPath();
					context.moveTo(x, y);
					context.lineTo(x2, y2);
					context.stroke();
				}
			}
		}
	
		let movingForwards = false;
		let movingBackwards = false;
		let zRotateLeft = false;
		let zRotateRight = false;
		let yRotateLeft = false;
		let yRotateRight = false;
		
		let lastBottomLipPos = null;
		
		// handle receiving facial landmark coordinate data 
		socket.on('landmarkCoordinates', (data) => {
			let landmark_data = JSON.parse(data);
			
			if(meshLoaded && landmark_data.length > 0){
			
			
				////////// start movement calculation stuff (i.e. determine how to rotate/translate head)
				if(calibrate){
					calibrate = !calibrate;
					prevAnchor = landmark_data[27];
					calibrateBaseline(landmark_data, mapping); // mapping defined above as empty dictionary
				}
			
				rightJawEnd = landmark_data[0];
				leftJawEnd = landmark_data[16];
				if(lastJawEndptDist === null){
					lastJawEndptDist = getDistance(leftJawEnd, rightJawEnd);
				}else{
					// note! moving the head up and down can trigger similar changes to moving backwards/forwards :<
					let currDist = getDistance(leftJawEnd, rightJawEnd);
					
					// how much room can we give before something is actually considered moving towards or away from the cam?
					// we should allow for some small dist changes before translating the avatar forwards or backwards
					if(currDist < lastJawEndptDist - 3){
						// moving backwards / away from camera 
						// by how much?
						movingBackwards = true;
						//document.getElementById('currentAction').textContent = "moving backwards...";
					}else if(currDist > lastJawEndptDist + 3){
						// moving forwards / towards camera
						//document.getElementById('currentAction').textContent = "moving forwards...";
						movingForwards = true;
					}
					
					// reset
					lastJawEndptDist = currDist;
				}
				

				if(mapping['mouth']){
					// now that we have shape keys for mouth movement, we only need to worry about how much we need to set the morphInfluence as given 
					// the current state of the facial landmarks 
					// but wait!! what about scaling? i.e. at calibration the face is at a certain distance from the camera, which affects the distance between 
					// points, right? wouldn't it be good to have some kind of scaling so we don't miscalculate?
					handleMouthMovement(mapping, landmark_data, avatarParts);
				}
				
				if(mapping['leftEye'] && mapping['rightEye']){
					handleEyeMovement(mapping, landmark_data, avatarParts);
				}
				
				if(mapping['leftEyebrow'] && mapping['rightEyebrow']){
					handleEyebrowMovement(mapping, landmark_data, avatarParts);
				}
				
				// are we rotating the head about the z-axis (the axis coming at the camera), i.e. head tilts sideways
				if(prevAnchor){
				
					currAnchor = landmark_data[27]; // we just need one point?

					//let currAnchor2 = landmark_data[30];
					let angle = getAngle(currAnchor, prevAnchor);
					
					if(Math.abs(angle) > 2 && !(inRange(leftJawEnd.y, rightJawEnd.y, 3.0))){
						//document.getElementById('zAxisRotation').textContent = "rotate about z-axis! angle: " + angle + " degrees.";
						updateAnchorPoint = true;
						if(angle > 0){
							zRotateRight = true;
						}else{
							zRotateLeft = true; 
						}
					}
				}
				
				// are we rotating about the y-axis (axis going up/down). captures head rotation when looking left/right
				// look at distance between nose point and jaw endpoints
				// uh but what if the head is tilted??? we can use the jaw endpoints to help (look at their y-values?)
				if(prevAnchor){
				
					currAnchor = landmark_data[27]; // we just need one point?
					
					// need to make sure the jaw endpoints are pretty much at the same level 
					// and check to see that the curr anchor pt. is 
					let diff = currAnchor.x - prevAnchor.x;
					let turnDirection = diff > 0.0 ? "left" : "right";
					
					if(inRange(leftJawEnd.y, rightJawEnd.y, 1.0) && !(inRange(currAnchor.x, prevAnchor.x, 2.0))){
						// if the curr pos of currAnchor1 is more than a certain amount away from the prev anchorPoint along the x-axis
						// and as long as the y-coords of the jaw endpoints are pretty similar
						updateAnchorPoint = true;
						if(turnDirection === "left"){
							yRotateLeft = true;
						}else{
							yRotateRight = true;
						}
					}
					
				}
				
				
				// are we rotating about the x-axis (axis going left/right). captures nodding motions.
				// can use nose anchor point and just check y-axis?
				if(updateAnchorPoint){
					prevAnchor = currAnchor;
					updateAnchorPoint = false;
				}
				
				
				// are we translating the head? i.e. moving the head left/right without any rotations?
				// just sample a few points and get the diff?
				
				/////////// end movement calculation stuff
				
				
				// update canvas with landmark coordinates
				let canvas = document.getElementById("display");
				let context = canvas.getContext("2d");
				updateCanvas(landmark_data, context);


				// update mesh
				if(movingForwards){
					// just update camera!
					camera.translateZ(-1.0);
					movingForwards = false;
				}else if(movingBackwards){
					movingBackwards = false;
					camera.translateZ(1.0);
				}
				
				// rotate about z axis
				if(zRotateLeft){
					if(group.rotation.z < (Math.PI / 3)){
						group.rotateOnWorldAxis(new THREE.Vector3(0,0,1), Math.PI / 8);
					}
					zRotateLeft = false;
				}else if(zRotateRight){
					if(group.rotation.z > (-Math.PI / 3)){
						group.rotateOnWorldAxis(new THREE.Vector3(0,0,1), -Math.PI / 8);
					}
					zRotateRight = false;
				}
				
				
				// rotate about y axis
				if(yRotateLeft){
					if(group.rotation.y < (Math.PI / 3)){
						// clamp the rotation
						group.rotateOnWorldAxis(new THREE.Vector3(0,1,0), Math.PI / 8);
					}
					yRotateLeft = false;
				}else if(yRotateRight){
					if(group.rotation.y > (-Math.PI / 3)){
						group.rotateOnWorldAxis(new THREE.Vector3(0,1,0), -Math.PI / 8);
					}
					yRotateRight = false;
				}
				
				renderer.render(scene, camera);
				
			}
		});
		
	</script>



</html>