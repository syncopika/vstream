<html>

	<!-- 
		this page is for exploring manipulating vertices of a geometry and to 
		experiment with some ideas on how to do that given real-time facial landmark data.
		
		good to know info: https://blender.stackexchange.com/questions/167372/gltf-export-has-twice-the-vertices-it-should
	-->

	<head>
		<title>vstream display</title>
		<!--<script src="//cdnjs.cloudflare.com/ajax/libs/socket.io/2.2.0/socket.io.js" integrity="sha256-yr4fRk/GU1ehYJPAs8P4JlTgu0Hdsp4ZKrx8bDEDC3I=" crossorigin="anonymous"></script>-->
		<script src='https://cdnjs.cloudflare.com/ajax/libs/three.js/108/three.min.js'></script>
		<script src='testing_stuff/GLTFLoader.js'></script>
	</head>
	
	<style>
		#main{
			font-family: monospace;
			text-align: center;
			top: 5%;
			position: relative;
			display: block;
		}
		#container{
			width: 400px;
			height: 400px;
			margin: 0 auto;
			border: #000 solid 1px;
		}
	</style>
	
	<body>
		<div id='main'>
			<h3> vstream display </h3>
			
			<div id='container'>
			</div>
			
			<br />
			<br />
			
			<button id='nextAction'> action </button>
			
		</div>
	</body>


	<script>
	
		const loader = new THREE.GLTFLoader();
		let loadedModels = [];
		let avatarVertices = null;
		let avatarGeometry = null;
		let avatar;
		let showWireframe = false;
		
		const avatarParts = {
			"head": null,
			"leftEyebrow": null,
			"leftEye": null,
			"rightEyebrow": null,
			"rightEye": null,
			"mouth": null
		};
		
		
		const raycaster = new THREE.Raycaster();
		const mouse = new THREE.Vector2(-1000, -1000);

		function onMouseMove(event) {
			// calculate mouse position in normalized device coordinates
			// (-1 to +1) for both components
			if(event.target.nodeName.toLowerCase() === "canvas"){
				mouse.x = ( event.clientX / 400 ) * 2 - 1;
				mouse.y = - ( event.clientY / 400 ) * 2 + 1;
				console.log("mouse x: " + mouse.x + ", mouse y: " + mouse.y)
			}
		}


		
		function extractVertices(vertices){
			//console.log(vertices.count);
			let vertexSet = [];
			// this for loop is wrong
			for(let i = 0; i <= vertices.count - 3; i += 3){
				let vertex = new THREE.Vector3();
				vertex.fromBufferAttribute(vertices, i);
				vertexSet.push(vertex);
			}
			return vertexSet;
		}
	
		function getModel(modelFilePath, name){
			return new Promise((resolve, reject) => {
				loader.load(
					modelFilePath,
					function(gltf){
						//console.log(gltf.scene);
						if(gltf.animations.length > 0){
							console.log(gltf.animations);
						}
						var faceParts = [];
						gltf.scene.traverse((child) => {

							if(child.type === "Mesh" || child.type === "SkinnedMesh"){
								
								let material = child.material;
								let geometry = child.geometry;
								let obj;

								if(child.type === "SkinnedMesh"){
									console.log(child);
									
									geometry.attributes.skinWeight.array[0] = 0;
									geometry.attributes.skinWeight.array[4] = 0;
									geometry.attributes.skinWeight.array[8] = 0;
									geometry.attributes.skinWeight.array[12] = 0;
									geometry.attributes.skinWeight.array[16] = 0;
									geometry.attributes.skinWeight.array[20] = 0;
									geometry.attributes.skinWeight.array[24] = 0;
									geometry.attributes.skinWeight.array[28] = 0;
									geometry.attributes.skinWeight.array[31] = 0;
									
									obj = new THREE.SkinnedMesh(geometry, material);
									obj.bind(child.skeleton);
									obj.add(child.skeleton.bones[0]);
									
									var helper = new THREE.SkeletonHelper(obj);
									helper.material.linewidth = 2;
									scene.add(helper);
								}else{
									obj = new THREE.Mesh(geometry, material);
								}
								
								// https://stackoverflow.com/questions/52569738/how-to-access-single-vertices-of-mesh-loaded-with-gltfloader-in-three-js
								
								obj.scale.x = child.scale.x * 5;
								obj.scale.y = child.scale.y * 5;
								obj.scale.z = child.scale.z * 5;

								obj.name = child.name;

								faceParts.push(obj);
								
							}else if(child.type === "Bone"){
								//console.log(child);
							}
						});
						resolve(faceParts);
					},
					// called while loading is progressing
					function(xhr){
						console.log( (xhr.loaded / xhr.total * 100) + '% loaded' );
					},
					// called when loading has errors
					function(error){
						console.log('An error happened');
						console.log(error);
					}
				);
			});
		}
			

		const el = document.getElementById("container");
		const renderer = new THREE.WebGLRenderer();
		const fov = 60;
		const camera = new THREE.PerspectiveCamera(fov, 1.0, 0.01, 1000);
		const scene = new THREE.Scene();
		scene.background = new THREE.Color(0xffffff);	
		
		renderer.shadowMap.enabled = true;
		renderer.setSize(400, 400);	
		el.appendChild(renderer.domElement);
		
		camera.position.set(0,2,20);
		scene.add(camera);

		// https://discourse.threejs.org/t/solved-glb-model-is-very-dark/6258
		// should always use a hemisphere light!
		var hemiLight = new THREE.HemisphereLight(0xffffff, 0x444444);
		hemiLight.position.set(0, 300, 0);
		scene.add(hemiLight);
		

		loadedModels.push(getModel('testing_stuff/basic_avatar_head-edit.gltf', 'avatar'));
		var group = new THREE.Group();
		
		Promise.all(loadedModels).then((objects) => {
			objects.forEach((meshList) => {
				
				var count = 0;
				
				// note that i'm assuming a list of meshes coming in. change this later
				meshList.forEach((mesh) => {
					//console.log(mesh);
					//console.log("------------------------")
					if(showWireframe){
						var wireframe = new THREE.WireframeGeometry(mesh.geometry);
						var line = new THREE.LineSegments(wireframe);
						line.material.depthTest = false;
						line.material.opacity = .8;
						line.material.transparent = true;
						group.add(line);
					}else{
						group.add(mesh);
					}
				
					bgAxesHelper = new THREE.AxesHelper(10);
					group.add(bgAxesHelper);
					//mesh.position.set(0,0,0);
					
					let theMesh = showWireframe ? line : mesh;
					let meshGeometry = showWireframe ? line.geometry : mesh.geometry;
					//console.log(meshGeometry);
					//console.log("===================")
					
					if(mesh.name === "head"){
						// the head 
						avatarParts.head = meshGeometry;
					}
					
					// loading the meshes is not always in the same order!!!
					if(mesh.name === "rightEye"){
						// right eye
						theMesh.position.set(-3.5,3,0);
						avatarParts.rightEye = meshGeometry;
					}
					
					if(mesh.name === "leftEye"){
						// left eye
						theMesh.position.set(3.5,3,0);
						avatarParts.leftEye = meshGeometry;
					}
					
					if(mesh.name === "leftEyebrow"){
						// left eyebrow
						theMesh.position.set(3.5,6.5,0);
						avatarParts.leftEyebrow = meshGeometry;
					}
					
					if(mesh.name === "rightEyebrow"){
						// right eyebrow
						theMesh.position.set(-3.5,6.5,0);
						avatarParts.rightEyebrow = meshGeometry;
					}
					
					if(mesh.name === "mouth"){
						// mouth
						theMesh.position.set(0,0,0);
						avatarParts.mouth = mesh; //meshGeometry;
					}
					
					count++;
					
					if(count === 6){
						console.log(avatarParts);
						group.position.set(0,0,0);
						avatar = group;
						scene.add(group);
						renderer.render(scene, camera);
						
						/*
						function render(){
							// update the picking ray with the camera and mouse position
							console.log("mouse x: " + mouse.x + ", mouse y: " + mouse.y)
							raycaster.setFromCamera(mouse, camera);

							// calculate objects intersecting the picking ray
							let intersects = raycaster.intersectObjects(scene.children, true);

							for (let i = 0; i < intersects.length; i++) {
								console.log(intersects[i])
								intersects[ i ].object.material.color.set( 0xff0000 );
								break;
							}

							renderer.render( scene, camera );
						}

						window.addEventListener( 'mousemove', onMouseMove, false );
						window.requestAnimationFrame(render);
						*/
					}
				});
			});
		});
		
		function moveVertex(vector3, x, y, z){
			vector3.set(x, y, z);
		}
		
		let currVertex = 0;
		function test1(){
			// try to stretch the avatar a bit
			// might be useful https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Iterators_and_Generators
			let part = avatarParts.mouth; //.rightEye;]
			let bottomMouthVerts = [5,6,11,20,21,22,24,26,27,29,30,31,32,33,35,36,37,38];
			let cornerMouthVerts = [7,9,10,14,18];
			
			avatarVertices = part.attributes.position.array;
			//console.log(verts.length);
			console.log(part)
		
			//let v = (currVertex++ % part.attributes.position.count)*3;
			//avatarVertices[v] = avatarVertices[v] + 5.50;
			//console.log("currently on vertex number: " + (currVertex - 1) % part.attributes.position.count);
			
			bottomMouthVerts.forEach((idx) => {
				let v = idx*3 + 1;
				avatarVertices[v] = avatarVertices[v] - 0.5;
				
				//console.log(idx)
				//console.log("x: " + avatarVertices[v-1] + ", y: " + avatarVertices[v] + ", z: " + avatarVertices[v+1])
				//console.log("==========================")
			});
			
			/*
			cornerMouthVerts.forEach((idx) => {
				let v = idx*3;
				if(idx === 14 || idx === 18 || idx === 10){
					avatarVertices[v] = avatarVertices[v] - 0.5;
				}else{
					avatarVertices[v] = avatarVertices[v] + 0.5;
				}
			});
			*/
			
			// https://stackoverflow.com/questions/20303239/three-js-how-to-update-buffergeometry-vertices
			// try this? https://stackoverflow.com/questions/36699389/verticesneedupdate-in-three-js/36699654#36699654
			// https://threejsfundamentals.org/threejs/lessons/threejs-custom-buffergeometry.html

			part.attributes.position.needsUpdate = true;
			renderer.render(scene, camera);
		}
		
		function moveLeftEye(){
		}
		
		function moveRightEye(){
		}
		
		function closeRightEye(){
		}
		
		function openRightEye(){
		}
		
		function moveMouth(){
			
		}
		
		function rotateFaceZ(){
			group.rotateZ(Math.PI / 8);
		}

		let angle = 0.0;
		function test2(){
			let mouth = avatarParts.mouth;
			let bone = mouth.children[0];
			console.log(mouth);
			angle -= 0.2;
			bone.rotation.x = angle;
		}

		document.getElementById('nextAction').addEventListener('click', (evt) => {
			test2();
			//rotateFaceZ();
			//test1();
			//moveRightEye();
			//moveLeftEye();
			//moveMouth();
			//closeRightEye()
			//avatar.rotateOnAxis(new THREE.Vector3(0,0,1), Math.PI/4); // degree of rotation can be a measure of 'sensitivity' maybe?
			//testMoveBody();
			//avatarParts.mouth.attributes.position.needsUpdate = true;
			//avatarGeometry.attributes.color.needsUpdate = true;
			renderer.render(scene, camera);
		});
		
		
		/*
		
			notes ----------------------
			
			7/29/20
			hmm this is pretty hard and I am getting sad. :/
			
			ok so maybe the server can be keeping track of relative changes and
			send commands over to the client to do them. hey, that sounds a lot like networking for games.
			
			i.e. do the eye vertices converge (i.e. eye closing).
			if so, then just send that action to the browser and the client-side 
			code can do the animation? 
			
			how can we take 2d coords and figure out what should be happening in 3d? is it even possible!?
		
			rotations should be not too bad right? we can start with that. i.e. if I rotate my head from one 
			side to the other, with just 2d coords can I know something about my head's rotation?
			
			alright, I decided to google it and found this: https://stackoverflow.com/questions/54368577/how-do-you-transform-2d-facial-landmarks-into-3d-world-coordinates
			
			:(, but not surprised. this looks helpful though: https://github.com/TadasBaltrusaitis/OpenFace
		
		*/
	
	</script>
	
</html>
